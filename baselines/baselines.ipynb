{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "0e10c6de-685a-4e93-9925-7d73cb27497c",
    "_uuid": "a0f7e95a8994cea779577c48c3d22cde3fdf2cc5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_auc_score, hamming_loss, accuracy_score \n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "# read data\n",
    "X_train = np.load('./data/X_train.npy')\n",
    "X_test = np.load('./data/X_test.npy')\n",
    "y_train = np.load('./data/y_train.npy')\n",
    "y_test = np.load('./data/y_test.npy')\n",
    "\n",
    "type_indicators = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\", \n",
    "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
    "\n",
    "\n",
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    \n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "    \n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c4c7a734-bffc-44dd-81b8-865b7161cd53",
    "_uuid": "2e834d2d4594b7b9e200784033b15b94d02afb54"
   },
   "source": [
    "### Vectorize with count and tf-idf\n",
    "\n",
    "Keep words appearing in 10% to 70 % of the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "fe473d3a-9f1d-48b0-8d97-0ff576ad4f10",
    "_uuid": "86f08653912e5643b959751ea17b794e4d3cbcdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer...\n",
      "Tf-idf...\n",
      "MBTI 1st row: ISFP\n",
      "Y: Binarized MBTI 1st row: [0 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'ability'),\n",
       " (1, 'able'),\n",
       " (2, 'absolutely'),\n",
       " (3, 'accept'),\n",
       " (4, 'accurate'),\n",
       " (5, 'across'),\n",
       " (6, 'act'),\n",
       " (7, 'action'),\n",
       " (8, 'actual'),\n",
       " (9, 'actually')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Posts to a matrix of token counts\n",
    "cntizer = CountVectorizer(analyzer=\"word\", \n",
    "                             max_features=1500, \n",
    "                             tokenizer=None,    \n",
    "                             preprocessor=None, \n",
    "                             stop_words=None,  \n",
    "                             max_df=0.7,\n",
    "                             min_df=0.1) \n",
    "\n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "print(\"CountVectorizer...\")\n",
    "X_train = cntizer.fit_transform(X_train)\n",
    "X_test = cntizer.transform(X_test)\n",
    "# Transform the count matrix to a normalized tf or tf-idf representation\n",
    "tfizer = TfidfTransformer()\n",
    "\n",
    "print(\"Tf-idf...\")\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "X_train =  tfizer.fit_transform(X_train).toarray()\n",
    "X_test =  tfizer.transform(X_test).toarray()\n",
    "print(\"MBTI 1st row: %s\" % translate_back(y_train[0,:]))\n",
    "print(\"Y: Binarized MBTI 1st row: %s\" % y_train[0,:])\n",
    "feature_names = list(enumerate(cntizer.get_feature_names()))\n",
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM - One vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.3319884726224784 \n",
      " roc_auc_score 0.6007018964536487 \n",
      " hamming_loss 0.2404899135446686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classif = OneVsRestClassifier(LinearSVC())\n",
    "classif.fit(X_train, y_train)\n",
    "y = classif.predict(X_test)\n",
    "print('accuracy_score', accuracy_score(y_test, y), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, y), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.3285302593659942 \n",
      " roc_auc_score 0.6273825065533728 \n",
      " hamming_loss 0.2489913544668588\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classif = ClassifierChain(LinearSVC())\n",
    "classif.fit(X_train, y_train)\n",
    "y = classif.predict(X_test)\n",
    "\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, y.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, Gaussian kernel - One vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.2904899135446686 \n",
      " roc_auc_score 0.5665363295727185 \n",
      " hamming_loss 0.24927953890489912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classif = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "classif.fit(X_train, y_train)\n",
    "y = classif.predict(X_test)\n",
    "\n",
    "print('accuracy_score', accuracy_score(y_test, y), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, y), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained SVM, Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.2881844380403458 \n",
      " roc_auc_score 0.5611140850486074 \n",
      " hamming_loss 0.2524495677233429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classif = ClassifierChain(SVC(gamma='scale'))\n",
    "classif.fit(X_train, y_train)\n",
    "y = classif.predict(X_test)\n",
    "\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, y.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLkNN(ignore_first_neighbours=0, k=10, s=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "X_train_mlknn = lil_matrix(X_train).toarray()\n",
    "y_train_mlknn = lil_matrix(y_train).toarray()\n",
    "X_test_mlknn = lil_matrix(X_test).toarray()\n",
    "\n",
    "classif = MLkNN()\n",
    "classif.fit(X_train_mlknn, y_train_mlknn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.2622478386167147 \n",
      " roc_auc_score 0.5658352239225045 \n",
      " hamming_loss 0.28285302593659944\n"
     ]
    }
   ],
   "source": [
    "y = classif.predict(X_test_mlknn)\n",
    "yp = classif.predict_proba(X_test_mlknn)\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "        order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# initialize classifier chains multi-label classifier\n",
    "classif = ClassifierChain(GaussianNB())\n",
    "classif.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.20922190201729107 \n",
      " roc_auc_score 0.6912461019993441 \n",
      " hamming_loss 0.33645533141210376\n"
     ]
    }
   ],
   "source": [
    "y = classif.predict(X_test)\n",
    "yp = classif.predict_proba(X_test)\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=BernoulliNB(alpha=1.0, binarize=None, class_prior=None, fit_prior=True),\n",
       "        order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "classif = ClassifierChain(BernoulliNB(alpha=1.0, binarize=None, class_prior=None, fit_prior=True))\n",
    "classif.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.2904899135446686 \n",
      " roc_auc_score 0.7198294564753879 \n",
      " hamming_loss 0.25994236311239194\n"
     ]
    }
   ],
   "source": [
    "y = classif.predict(X_test)\n",
    "yp = classif.predict_proba(X_test)\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained BaggedBernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=BaggingClassifier(base_estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "        order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "classif = ClassifierChain(BaggingClassifier(base_estimator=BernoulliNB()))\n",
    "classif.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.2685878962536023 \n",
      " roc_auc_score 0.7004657857359968 \n",
      " hamming_loss 0.2889048991354467\n"
     ]
    }
   ],
   "source": [
    "y = classif.predict(X_test)\n",
    "yp = classif.predict_proba(X_test)\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained Adaboost with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.1642651296829971 \n",
      " roc_auc_score 0.5412128136372868 \n",
      " hamming_loss 0.3612391930835735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classif = ClassifierChain(AdaBoostClassifier(base_estimator=DecisionTreeClassifier()))\n",
    "classif.fit(X_train, y_train)\n",
    "y = classif.predict(X_test)\n",
    "yp = classif.predict_proba(X_test)\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.3504322766570605 \n",
      " roc_auc_score 0.7446379886968562 \n",
      " hamming_loss 0.23631123919308358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classif = ClassifierChain(LogisticRegression(solver='lbfgs'))\n",
    "classif.fit(X_train, y_train)\n",
    "y = classif.predict(X_test)\n",
    "yp = classif.predict_proba(X_test)\n",
    "print('accuracy_score', accuracy_score(y_test, y.toarray()), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp.toarray()), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classif = RandomForestClassifier(n_estimators=100, class_weight=None)\n",
    "classif.fit(X_train, y_train)\n",
    "y = classif.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.30086455331412104 \n",
      " roc_auc_score 0.6340715137209887 \n",
      " hamming_loss 0.2695965417867435\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score', accuracy_score(y_test, y), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, y), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCNN (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dainis/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classif = MLPClassifier()\n",
    "classif.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.30086455331412104 \n",
      " roc_auc_score 0.7124481967804894 \n",
      " hamming_loss 0.2695965417867435\n"
     ]
    }
   ],
   "source": [
    "y = classif.predict(X_test)\n",
    "yp = classif.predict_proba(X_test)\n",
    "print('accuracy_score', accuracy_score(y_test, y), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

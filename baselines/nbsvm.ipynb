{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "0e10c6de-685a-4e93-9925-7d73cb27497c",
    "_uuid": "a0f7e95a8994cea779577c48c3d22cde3fdf2cc5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from sklearn.metrics import roc_auc_score, roc_auc_score, hamming_loss, accuracy_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "\n",
    "# read data\n",
    "train = np.load('../data/X_train.npy')\n",
    "test = np.load('../data/X_test.npy')\n",
    "y_train = np.load('../data/y_train.npy')\n",
    "y_test = np.load('../data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "8ab0a44e-70c7-4876-aa9c-fd6a552ecf94",
    "_uuid": "5c0185231d1dec0773ac8574677dec7a641d5409"
   },
   "outputs": [],
   "source": [
    "type_indicators = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\", \n",
    "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
    "\n",
    "\n",
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    \n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "    \n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBSVM:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        \n",
    "    def _pr(self, y_i, y):\n",
    "        p = self.X[y==y_i].sum(0)\n",
    "        return (p+1) / ((y==y_i).sum()+1)\n",
    "    \n",
    "    def _get_mdl(self, y):\n",
    "        r = np.log(self._pr(1,y) / self._pr(0,y))\n",
    "        m = LogisticRegression(C=4.0, class_weight='balanced', dual=True, solver='liblinear')\n",
    "        x_nb = self.X.multiply(r)\n",
    "        return m.fit(x_nb, y), r\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.models = []\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        for j in range(self.Y.shape[1]):\n",
    "            m,r = self._get_mdl(self.Y[:,j])\n",
    "            self.models.append((m, r))\n",
    "            \n",
    "        pass\n",
    "\n",
    "    def predict_probas(self, X):\n",
    "        probas = np.zeros((X.shape[0], self.Y.shape[1]))\n",
    "        for i, m in enumerate(self.models):\n",
    "            probas[:,i] = m[0].predict_proba(X.multiply(m[1]))[:,1]\n",
    "        return probas\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicts = np.zeros((X.shape[0], self.Y.shape[1]))\n",
    "        for i, m in enumerate(self.models):\n",
    "            predicts[:,i] = m[0].predict(X.multiply(m[1]))\n",
    "        return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "fe473d3a-9f1d-48b0-8d97-0ff576ad4f10",
    "_uuid": "86f08653912e5643b959751ea17b794e4d3cbcdc"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2), \n",
    "               min_df=10, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "X_train =  vec.fit_transform(train)\n",
    "X_test =  vec.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = NBSVM()\n",
    "classif.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = classif.predict(X_test)\n",
    "yp = classif.predict_probas(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.37060518731988473 \n",
      " roc_auc_score 0.7651928012590137 \n",
      " hamming_loss 0.22146974063400576\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score', accuracy_score(y_test, y), '\\n',\n",
    "      'roc_auc_score', roc_auc_score(y_test, yp), '\\n',\n",
    "      'hamming_loss', hamming_loss(y_test, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYKc7QpVtgwN"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "type_indicators = [\"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\",\n",
    "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"]\n",
    "\n",
    "b_Pers = {'I': 0, 'E': 1, 'N': 0, 'S': 1, 'F': 0, 'T': 1, 'J': 0, 'P': 1}\n",
    "b_Pers_list = [{0: 'I', 1: 'E'}, {0: 'N', 1: 'S'}, {0: 'F', 1: 'T'}, {0: 'J', 1: 'P'}]\n",
    "\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    personality = personality.upper()\n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "\n",
    "def translate_personality_flair(personality):\n",
    "    # transform mbti to binary vector\n",
    "    personality = personality.upper()\n",
    "    #return [\"__label__\" + str(b_Pers[l]) for l in personality]\n",
    "    return [\"__label__\"+str(l) for l in personality]\n",
    "\n",
    "\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "\n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n",
    "\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def chunkstring(array, length):\n",
    "    array = array.replace('\\n','').split()\n",
    "    cleaned_array = []\n",
    "    for item in array:\n",
    "        if isEnglish(item):\n",
    "            cleaned_array.append(item)\n",
    "    chuncked = [' '.join(cleaned_array[jj: jj + length]) for jj in range(0,  len(cleaned_array), length)\n",
    "                if len(cleaned_array[jj: jj + length]) != 0]\n",
    "\n",
    "    chuncked = [ch for ch in chuncked if len(ch)>100]\n",
    "    if len(chuncked)==0:\n",
    "        print('chunk with less than 100 words won\\'t be considered : ', array)\n",
    "    return chuncked\n",
    "\n",
    "\n",
    "def get_chk_no(text, length):\n",
    "    #array = array.replace('\\n','').split(' ')\n",
    "    text = text.replace('\\n', '')\n",
    "    array = text.split()\n",
    "    cleaned_array = []\n",
    "    for item in array:\n",
    "        if isEnglish(item):\n",
    "            cleaned_array.append(item)\n",
    "    chuncked = [' '.join(cleaned_array[jj: jj + length]) for jj in range(0,  len(cleaned_array), length)\n",
    "                if len(cleaned_array[jj: jj + length]) != 0]\n",
    "    chuncked = [ch for ch in chuncked if len(ch) > 100]\n",
    "    return len(chuncked)\n",
    "\n",
    "\n",
    "def clean_data(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '[URL]', text)\n",
    "    return re.sub(r'(^<U.*>$|<f0>)', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_1sMabLtokR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "utils.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
